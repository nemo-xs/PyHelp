# region #* импорт библиотек, работа с библиотеками ---------------------------
import os
import time
import multiprocessing as mp  # стандартный модуль, импорт класса
# для управления процессами
from threading import Thread  # импорт класса стандарнтного модуля управления
# потоками
import threading
import asyncio
from concurrent.futures import ThreadPoolExecutor, as_completed  # импорт
# класса для создания пула потоков
from queue import Queue  # импорт класса управления синхронизацией потоков
import socket  # импорт библиотеки взаимодействия с сокетами

import re  # импорт библиотеки разбора фраз, предложений и т.п. по маске
import requests

import dotenv  # импорт python-dotenv (см virtualenv.md), создание и вызов
dotenv.load_dotenv()  # системных переменных окружения, паролей из файла .env
name = os.getenv('MYNAME')

# endregion -------------------------------------------------------------------

# region #* Процесс и его характериситики -------------------------------------
"""процесс — это программа, которая запущена в оперативной памяти компьютера.
Процесс — это набор инструкций, которые выполняются последовательно.
Все процессы изолированны от других процессов. У каждого из них свои:
• виртуальное адресное пространство,
• указатель на исполняемую инструкцию,
• стек вызовов,
• системные ресурсы, например, открытые файловые дескрипторы.
"""
pid = os.getpid()  # получение идентификатора процесса
count = 2  # счетчик
while count:
    """цикл выводит номер процесса, системное время.. пауза 2 сек и снова.."""
    print(pid, time.time())
    time.sleep(1)
    count -= 1
# endregion -------------------------------------------------------------------

# region #* Создание подпроцессов pid -----------------------------------------

""" #_ вариант мультипроцессорности только для linux
foo = 'bar'
pid = os.fork()  # создание дочернего процесса (точная копия родителя) c pid=0
if pid == 0:  # pid дочернего процесса равен 0, память скопирована с родителя
    foo = 'zzz'  # переопределение переменной только для дочернего процесса
    print("Chaild process", os.getpid(), foo)
else:
    print("Parent process", os.getpid(), foo)
"""


# _ вариант мультипроцессорности (запуск через if __name ==__main__)
# def f(name):
#     print("hello", name)


# """Данный вариант работает через модуль multiprocessing стандартной
# библиотеки. Создается экземпляр класса Process в который передается часть
# кода и аргументы для этого кода (если они им принимаются)
# """
# p = Process(target=f, args=('Bob',))  # процесс пока не запущен
# p.start()  # запуск дочернего процесса
# p.join()  # завершение дочернего процесса


# _ создание методом ООП (запуск также через if __name == __main__)
# class PrintProcess(mp.Process):
#     def __init__(self, name):
#         super().__init__()
#         self.name = name

#     def run(self):
#         print("Hello", self.name)


# p = PrintProcess("Mike")
# p.start()
# p.join()
# endregion -------------------------------------------------------------------

# region #* Создание потоков --------------------------------------------------
"""С прикладной точки зрения поток целиком и полностью напоминает процесс.
Он имеет свою последовательность инструкций для исполнения, у каждого потока
есть свой собственный стек, но все потоки выполняются в рамках одного процесса.
Этим они отличаются. Если мы говорили о процессах и у каждого процесса были
свои ресурсы и память, то все созданные потоки разделяют память процесса и все
его ресурсы. Управлением и выполнением потоков занимается операционная система.
Пример логичного разделения потоков - работа с базой данных. Первый пишет в нее
второй, читает, третий - управляет состоянием.
Потоки находятся в модуле threading
При создании потоку можно указать имя. По умолчанию оно 'Thread-N'.
Переименовывать имеет смысл для дебага и отладки"""
Thread(name="NumberCrucher").name  # указание имени потока
"""
"""


# _ через создание экземпляра класса Thread
def t(name):
    """функция вызываемая в отдельном потоке, через вызов ниже"""
    print("Hello", name)


# Создается экземпляр класса Thread, для запуска в отдельном потоке в него
# передается функция (или часть кода) и аргументы для этого кода (если они им
# принимаются). Плюс в том, что решение запускать функцию отдельным потоком или
# нет, принимается для каждого экземпляра отдельно (в отличие от наследования)
th = Thread(target=t, args=("Mark",))

th.start()  # запуск отдельного потока

# Устновка потока в режим daemon. Используется чтобы поток автоматически
# уничтожался при выходе из интерпритатора. При таком подходе, процедура
# финализации не используется. Не использовать для работы с рессурсами (файлы,
# базы данных, сокеты,...) Так как рессурсы не освобождаются при таком закрытии
th.daemon  # поток daemon=True

th.ident  # У кажого потока есть уникальный идентификатора потока
th.is_alive()  # узнать запущен ли поток
th.join()  # после вызова принимает код, ждет его исполнения и завершает поток.


# _ через создание дочернего класса от Thread (наследование)
class PrintProcess(Thread):
    """Создание класса дочернего к Thread. Переопределение у него __init__"""
    def __init__(self, name):
        super().__init__()
        self.name = name
        # self._running = True - для реализации terminate

    def terminate(self):
        """В Python нет встроенного механихма завершения потоков. Для его
        реализации надо вставлять указанную конструкцию, и через вызов метода
        .terminate() можно принудительно завершить поток.
        Для реализации необходимо в __init__ self._running = True, а метод
        run запускать с циклом внутри метода run: while self._runing:
        """
        self._running = False

    def run(self):
        """переопределени метода run, который является частью .start() и
        запускается при вызове .start(). Теперь все создаваемые экземпляры
        PrintProcess будут запускаться в отдельном потоке"""
        # while self._runing: - для реализации terminate
        print("Hello", self.name)


p = PrintProcess("Mike")
p.start()  # запуск отдельного потока. При этом он не завершится самостоятельно
p.join()  # ждет исполнения кода и завершает поток
p.terminate()  # принудительно завершить поток


# _ Создание пула потоков
def cw(args):
    """функция возведения аргумента в квадрат"""
    return args * args


with ThreadPoolExecutor(max_workers=3) as pool:
    """через контекстный менеджер with вызываем класс управляющий пулом потоков
    где в качестве аргументов передаем максимально возможное количество потоков
    и присваиваем переменную pool"""
    results = [pool.submit(cw, i) for i in range(10)]
    """через for прогоняем range, в качестве аргумента передавая функцию cw, и
    результат submit(объект который еще не завершен и выполняется, но будет
    завершен в будущем.. Метод concurrent.futures.Future)
    """

    for future in as_completed(results):
        """as_completed позволяет дождаться завершения выполнения созданных
        потоков"""
        print(future.result(), end=" ")
# .shutdown() in exit - вызывается сама при завершении контекста with
# endregion -------------------------------------------------------------------

# region #* Синхронизация потоков ---------------------------------------------


def follow(connection, connection_lock, q):
    """Примитивы синхронизации в модуле threading:
    https://youtu.be/nR8WhdcRJwM?t=1794
    Lock() - обычный мьютекс для обеспечения эксклюзива доступа к состоянию
    RLock() - рекурсивный мьютекс разрешающий потоку владеющему мьютексом,
    захватить мьютекс более одного раза #_(по стандарту лучше использовать его)
    Semaphore() - вариация мьютекса, разрешающая захватить себя фикс кол-во раз
    BoundedSemaphore() - семафор который следит за тем, чтобы его захватили и
    отпустили одинаковое количество раз.
    Condition() - используется для отправки сигналов между потоками
    wait() - блокирует вызывающий поток пока другой поток не вызовет notify
    Все примитивы синхронизации реализуют единый интерфейс методами:
    .asquire() - захватывает примитив синхронизации
    .release() - отпускает захваченный примитив синхронизации
    """
    try:
        while True:
            connection_lock.asquire()
            message = connection.read_message()
            connection_lock.release()
            # with connection_lock:  # строки сверху, если использовать with
            #     message = connection.read_message()
            q.put(message)
    except requests.InvalidMessage:
        follow(connection, connection_lock, q)


follower = Thread(target=follow, args=[1, 2])
follower.start()
follower.join()

# _ Атракцион "Очередь" -----------------------------------------------------
"""Если запустить несколько потоков для решения задачи, придётся обмениваться
данными между потоками. Для этого понадобится модуль queue, и очередь, для
обмена данными между потоками.
Queue - FIFO очередь. Класс. Вместо него можно использовать контейнер deque
LifoOueue - LIFO очередь, или стек. Список
PriorityQueue - очередь, элементы который пары вида (priority, item) - список
"""


def worker(q, n):
    """Функция worker будет выполняться в двух независимых потоках,параллельно.
    Каждый поток в бесконечном цикле будет получать сообщение из очереди при
    помощи вызова метода get у объекта q."""
    while True:
        item = q.get()
        if item is None:
            break
        print("Process data:", n, item)


q = Queue(5)  # Создаётся объект типа очередь с макс размером 5.
th1 = Thread(target=worker, args=(q, 1))
th2 = Thread(target=worker, args=(q, 2))
# Для обработки сообщений этой очереди создаётся пара потоков — это объекты
# класса Thread, в эти объекты передается функция worker,и этой функции
# передаётся очередь (q).
th1.start()
th2.start()

for i in range(8):
    """ Для помещения элементов в очередь необходимо использовать метод put для
    объекта queue. Если в очереди будет уже пять элементов, то вызов метода put
    заблокирует выполнение потока, который вызвал этот метод, и будет ждать,
    пока не появится в очереди свободное место."""
    q.put(i)

"""Большое внимание нужно уделить правильному завершению потока.
С точки зрения процесса, ресурсами владеет процесс, то есть выделенная память
или открытый файл — ими владеет процесс. Но процесс ничего не знает о том, что
делает с этими ресурсами поток. И если поток завершить аварийно, то файл может
остаться незакрытым, блокировка может остаться невысвобожденной, и теоретически
это может привести к непредвиденным последствиям.Поэтому в Python не существует
функции аварийного завершения потока. Очень важно делать это правильно в
функции самого потока. Для этого в очередь помещается значение None, и функция
потока при проверке условия завершает свою работу."""
q.put(None)
q.put(None)
th1.join()
th2.join()

# endregion -------------------------------------------------------------------

# region #* Синхронизация потоков через условные переменные -------------------
""" Это очередь, с которой нужно будет работать в большом количестве потоков.
У неё есть операции put и get, и, конечно же, у неё есть какой-то размер.
Очередь не должна расти больше заданного размера. Если мы выполним операцию
put, а в очереди уже достаточно большое количество элементов, то нам необходимо
ждать пока это количество уменьшится. Вопрос — сколько ждать? Неизвестно.
Ответа на этот вопрос мы не получим. Для решения подобной задачи можно
использовать условные переменные.
Условные переменные (_mutex)в конструкторе получает объект блокировки. Он есть
по умолчанию, но если у нас эти переменные взаимозависимые, то необходимо
использовать общую блокировку. И при помощи этих условных переменных очень
легко и удобно ожидать событий при помощи вызова wait и оповещать все потоки,
которые сейчас ждут наступления этого события. Таким образом, очень легко и
удобно можно реализовать очередь в Python, которая работает в многопоточной
программе."""


class Queue(object):
    def __init__(self, size=5):
        self._size = size
        self._queue = []
        self._mutex = threading.RLock()  # объект блокировки в условную
        # переменную (приватную)
        self._empty = threading.Condition(self._mutex)  # атрибут- объект блока
        self._full = threading.Condition(self._mutex)  # атрибут- объект блока

    def put(self, val):
        with self._full:
            while len(self._queue) >= self._size:
                self._full.wait()  # ожидание
            self._queue.append(val)
            self._empty.notify()  # оповещение

    def get(self):
        with self._empty:
            while len(self._queue) == 0:
                self._empty.wait()

        ret = self._queue.pop(0)
        self._full.notify()
        return ret

# endregion -------------------------------------------------------------------

# region #* Синхронизация потоков через блокировки ----------------------------


""" предпочтительнее использовать простые очереди (выше) при разработке
многопоточных программ. Но, иногда приходится использовать блокировки.
Блокировки как минимум замедляют работу программы. Тем не менее, иногда их
приходится применять.
Предположим, что мы создали объект класса Точка и используем этот объект в
большом количестве потоков. Эти потоки, некоторые вызывают метод get, некоторые
вызывают метод set. Если бы не было блокировок, то может возникнуть такая
ситуация, когда один поток изменил значение переменной x или координаты x, а
другой поток в это время вернул координаты x и y. Мы получили неконсистентное
состояние объекта, когда у него частично одна координата изменена,а вторая нет.
Для того чтобы избежать подобных ситуаций, и нужны блокировки."""


class Point(object):
    """ есть класс Точка, и у класса Точка есть координаты x и y. Также у этого
    класса есть метод get, который возвращает эти координаты,и метод set,
    который задаёт новые координаты.
    В данном примере блокировка реализована через испольщование контекстного
    менеджера with который ничего не отдаст на выход пока не завершит работу"""
    def __init__(self):
        self._mutex = threading.RLock()  # объект блокировки (модуль threading)
        self._x = 0
        self._y = 0

    def get(self):
        """Создаём объект блокировки, и при помощи контекстного менеджера мы
        захватываем блокировку, а при выходе из контекстного менеджера
        блокировка высвобождается. Также для set"""
        with self._mutex:
            return (self._x, self._y)

    def set(self, x, y):
        with self._mutex:
            self._x = x
            self._y = y


# -----------------------------------------------------------------
""" #_ Блокировки можно создавать и без контекстного менеджера with.
Для этого создаём объекты класса RLock и затем вызываем методы acquire — это
получить или захватить блокировку и метод release для того, чтобы высвободить
её."""
a = threading.RLock()
b = threading.RLock()


def foo():
    try:
        a.acquire()  # захват блокировки
        b.acquire()
    finally:
        a.release()  # высврбождение блокировки
        b.release()


""" Если запустить подобный код в большом количестве процессов, то рано или
поздно это приведёт к ситуации, которая называется deadlock. Дело в том, что
блокировки освобождаеются в неправильной последовательности. Нужно отдавать
предпочтение использованию контекстного менеджера при работе с блокировками"""
# endregion -------------------------------------------------------------------

# region #* Глобальная блокировка интерпретатора GIL, asincio -----------------
""" Параллелизм и конкурентность
Если каждая очередь стоит к своему объекту - это Parallel
Если несколько очередей стоят к одному объекту - Concurency

GIL очень тесно связан с выполнением потоков, и для более глубокого
понимания того, как работают потоки в Python, нужны общие сведения о том,
как устроен и как работает GIL в Python. GIL это такая штука, которая не
позволяет одновременно двум потокам выполняться на одном ядре процессора,
даже если этих ядер у процессора несколько. Тем не менее, GIL в первую очередь
предназначен для защиты памяти интерпретатора от разрушений и делает все
операции с памятью атомарными.
GIL внутри реализован как обычная нерекурсивная блокировка, или объект класса
threading lock. Все потоки спят пять миллисекунд в ожидании получения
блокировки, и в Python 3, если работает один главный поток, то он не требует
освобождения этой глобальной блокировки интерпретатора.

GIL можно отключать, если в середине кода надо вставить блок на С или блок
использующий только системные операции. Синтаксис для отключения GIL:
Py_BEGIN_ALLOW_THREADS
_ блок системного кода
_ или кода на С
Py_END_ALLOW_THREADS
"""
"""
Модуль asincio используется для создания многопоточности в генераторах и
сопрограммах.
"""


async def echo(source, target):
    while True:
        line = await source.readline()
        if not line:
            break
        target.write(line)


# loop = asyncio.get_event_loop()
# server = asyncio.start_server(echo, port=8080)
# loop.create_task(server)

# try:
#     loop.run_forever()
# finally:
#     server.close()
#     loop.close()
# endregion -------------------------------------------------------------------
